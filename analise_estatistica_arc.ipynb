{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c999cd",
   "metadata": {},
   "source": [
    "# Análise Estatística: Efeitos do Estresse e Estratégia de Aprendizagem na Memória\n",
    "\n",
    "**Projeto:** Investigação da interação entre estresse induzido (TSST-G) e estratégias de aprendizagem (Releitura vs. Prática de Lembrar) no desempenho da memória (Evocação Livre e Organização - ARC).\n",
    "\n",
    "**Objetivo deste Notebook:** Realizar as análises estatísticas principais para testar as hipóteses do estudo, verificar a eficácia da manipulação experimental e explorar os dados, incorporando as melhores práticas discutidas e informações metodológicas.\n",
    "\n",
    "**Versão dos Dados:** `measures_phd_valid.csv` (Dados preliminares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3581b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importação de Bibliotecas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests # Para correção de múltiplas comparações\n",
    "import pingouin as pg # Para testes de pressupostos e tamanhos de efeito\n",
    "import os\n",
    "\n",
    "# Configurações de Visualização\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# Diretório para salvar outputs (gráficos, tabelas)\n",
    "output_dir = \"/home/ubuntu/projeto_analise_dados/analises_output_excel\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- Importações adicionais para Excel ---\n",
    "\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.drawing.image import Image\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles import Font, Alignment\n",
    "from math import sqrt\n",
    "\n",
    "# --- Funções Auxiliares para Formatação APA e Excel (v5) ---\n",
    "def get_degrees_freedom(model_or_df, source=None):\n",
    "    \"\"\"Helper to extract degrees of freedom robustly.\"\"\"\n",
    "    try:\n",
    "        if isinstance(model_or_df, pd.DataFrame): # Pingouin ANOVA table\n",
    "            if source:\n",
    "                # Handle potential multi-index or different source names in 3-way ANOVA\n",
    "                if source in model_or_df[\"Source\"].tolist():\n",
    "                    df_effect = model_or_df.loc[model_or_df[\"Source\"] == source, \"DF\"].iloc[0]\n",
    "                else:\n",
    "                    df_effect = \"err\" # Source not found\n",
    "                if \"Residual\" in model_or_df[\"Source\"].tolist():\n",
    "                     df_error = model_or_df.loc[model_or_df[\"Source\"] == \"Residual\", \"DF\"].iloc[0]\n",
    "                else:\n",
    "                     df_error = \"err\" # Residual not found\n",
    "                return int(df_effect) if isinstance(df_effect, (int, float)) else df_effect, \\\n",
    "                       int(df_error) if isinstance(df_error, (int, float)) else df_error\n",
    "            else: # Assume first row is effect, last is residual if source not specified (less robust)\n",
    "                df_effect = model_or_df[\"DF\"].iloc[0]\n",
    "                df_error = model_or_df[\"DF\"].iloc[-1]\n",
    "                return int(df_effect), int(df_error)\n",
    "        elif hasattr(model_or_df, \"df_num\") and hasattr(model_or_df, \"df_den\"): # Statsmodels fit results\n",
    "            return int(model_or_df.df_num), int(model_or_df.df_den)\n",
    "        elif hasattr(model_or_df, \"DF\"): # Pingouin t-test table\n",
    "             return int(model_or_df[\"DF\"].iloc[0])\n",
    "    except (IndexError, TypeError, KeyError):\n",
    "        return \"err\", \"err\" # Return error string if extraction fails\n",
    "    return \"err\", \"err\"\n",
    "\n",
    "def format_p_value(p):\n",
    "    \"\"\"Formats p-value according to APA style.\"\"\"\n",
    "    if pd.isna(p):\n",
    "        return \"p = n.s.\"\n",
    "    p = float(p)\n",
    "    if p < 0.001:\n",
    "        return \"p < .001\"\n",
    "    elif p < 0.01:\n",
    "        return f\"p = {p:.3f}\"[1:] # Remove leading zero\n",
    "    elif p < 0.05:\n",
    "        return f\"p = {p:.3f}\"[1:]\n",
    "    else:\n",
    "        return f\"p = {p:.3f}\"[1:]\n",
    "\n",
    "def format_stat(value):\n",
    "    \"\"\"Formats F or t value.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return \"N/A\"\n",
    "    return f\"{float(value):.2f}\"\n",
    "\n",
    "def format_eta_squared(value):\n",
    "    \"\"\"Formats eta-squared.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return \"N/A\"\n",
    "    if float(value) < 0.001:\n",
    "         return \"η²p < .001\"\n",
    "    return f\"η²p = {float(value):.3f}\"[1:]\n",
    "\n",
    "def format_cohen_d(value):\n",
    "    \"\"\"Formats Cohen's d.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return \"N/A\"\n",
    "    return f\"d = {float(value):.2f}\"\n",
    "\n",
    "def format_anova_apa_v5(aov_table, dv_name):\n",
    "    \"\"\"Formats 2x2x2 ANOVA results in APA style (v5).\"\"\"\n",
    "    if aov_table is None or aov_table.empty:\n",
    "        return f\"Análise ANOVA para {dv_name} não pôde ser realizada.\"\n",
    "        \n",
    "    results = []\n",
    "    # Define the order of effects for reporting (main effects, 2-way, 3-way)\n",
    "    source_order = [\n",
    "        \"Group\", \"Strategy\", \"nback_performance\", \n",
    "        \"Group * Strategy\", \"Group * nback_performance\", \"Strategy * nback_performance\",\n",
    "        \"Group * Strategy * nback_performance\"\n",
    "    ]\n",
    "    \n",
    "    # Filter sources present in the table and maintain order\n",
    "    sources_in_table = [s for s in source_order if s in aov_table[\"Source\"].tolist()]\n",
    "    \n",
    "    text = f\"Uma ANOVA fatorial 2 (Grupo: Controle, Estressado) x 2 (Estratégia: Releitura, Prática de Lembrar) x 2 (Desempenho N-Back: Baixo, Alto) foi conduzida para examinar os efeitos na variável {dv_name}. \"\n",
    "    \n",
    "    for source in sources_in_table:\n",
    "        row = aov_table[aov_table[\"Source\"] == source]\n",
    "        if row.empty:\n",
    "            continue\n",
    "        \n",
    "        f_val = row[\"F\"].iloc[0]\n",
    "        p_val = row[\"p-unc\"].iloc[0]\n",
    "        eta_sq = row[\"n2p\"].iloc[0]\n",
    "        df_effect, df_error = get_degrees_freedom(aov_table, source)\n",
    "        \n",
    "        # Describe the effect type\n",
    "        if \"*\" in source:\n",
    "            effect_desc = f\"a interação {source.replace('nback_performance', 'N-Back')}\"\n",
    "        else:\n",
    "            effect_desc = f\"o efeito principal de {source.replace('nback_performance', 'N-Back')}\"\n",
    "        significance = \"não foi significativo\" if p_val >= 0.05 else \"foi significativo\"\n",
    "        \n",
    "        # Handle potential errors in df extraction\n",
    "        if df_effect == \"err\" or df_error == \"err\":\n",
    "            f_string = f\"*F*(gl_efeito?, gl_erro?) = {format_stat(f_val)}\"\n",
    "        else:\n",
    "            f_string = f\"*F*({df_effect}, {df_error}) = {format_stat(f_val)}\"\n",
    "            \n",
    "        results.append(f\"{effect_desc} {significance}, {f_string}, {format_p_value(p_val)}, {format_eta_squared(eta_sq)}\")\n",
    "        \n",
    "    # Join the results grammatically\n",
    "    if len(results) == 0:\n",
    "        text += \"Nenhum efeito pôde ser analisado.\"\n",
    "    elif len(results) == 1:\n",
    "        text += results[0] + \".\"\n",
    "    else:\n",
    "        text += \", \".join(results[:-1]) + \" e \" + results[-1] + \".\"\n",
    "        \n",
    "    return text\n",
    "\n",
    "def format_ttest_apa(ttest_table, comparison_desc, group1_desc=None, group2_desc=None, m1=None, sd1=None, m2=None, sd2=None):\n",
    "    \"\"\"Formats t-test results in APA style.\"\"\"\n",
    "    if ttest_table is None or ttest_table.empty:\n",
    "        return f\"Teste t para {comparison_desc} não pôde ser realizado.\"\n",
    "        \n",
    "    row = ttest_table.iloc[0]\n",
    "    t_val = row[\"T\"]\n",
    "    p_val = row[\"p-val\"]\n",
    "    d_val = row[\"cohen-d\"]\n",
    "    df_val = get_degrees_freedom(ttest_table)\n",
    "    test_type = \"pareado\" if row[\"paired\"] else \"de amostras independentes\"\n",
    "    alternative = row[\"alternative\"]\n",
    "    tail = \"unilateral\" if alternative != \"two-sided\" else \"bilateral\"\n",
    "    \n",
    "    significance = \"não foi significativa\" if p_val >= 0.05 else \"foi significativa\"\n",
    "    \n",
    "    text = f\"Um teste t {test_type} ({tail}) indicou que a diferença {comparison_desc} {significance}, *t*({df_val}) = {format_stat(t_val)}, {format_p_value(p_val)}, {format_cohen_d(d_val)}.\"\n",
    "    \n",
    "    # Add means and SDs if provided\n",
    "    if test_type == \"de amostras independentes\" and m1 is not None and sd1 is not None and m2 is not None and sd2 is not None and group1_desc and group2_desc:\n",
    "        comparison_word = \"similares\"\n",
    "        if significance == \"foi significativa\":\n",
    "            comparison_word = \"maiores\" if m1 > m2 else \"menores\"\n",
    "        text += f\" O grupo {group1_desc} (*M* = {m1:.2f}, *DP* = {sd1:.2f}) apresentou escores {comparison_word} em comparação ao grupo {group2_desc} (*M* = {m2:.2f}, *DP* = {sd2:.2f}).\"\n",
    "    elif test_type == \"pareado\" and m1 is not None and sd1 is not None and m2 is not None and sd2 is not None:\n",
    "         text += f\" Os escores mudaram de (*M* = {m1:.2f}, *DP* = {sd1:.2f}) para (*M* = {m2:.2f}, *DP* = {sd2:.2f}).\"\n",
    "         \n",
    "    return text\n",
    "\n",
    "def format_mediation_apa(mediation_results):\n",
    "    \"\"\"Formats mediation analysis results in APA style.\"\"\"\n",
    "    if mediation_results is None or mediation_results.empty:\n",
    "        return \"Análise de mediação não pôde ser realizada.\"\n",
    "\n",
    "    try:\n",
    "        # Extract relevant paths and values\n",
    "        indirect_effect = mediation_results.loc[mediation_results[\"path\"] == \"Indirect\", \"coef\"].iloc[0]\n",
    "        indirect_pval = mediation_results.loc[mediation_results[\"path\"] == \"Indirect\", \"pval\"].iloc[0]\n",
    "        indirect_ci_lower = mediation_results.loc[mediation_results[\"path\"] == \"Indirect\", \"CI[2.5%]\"].iloc[0]\n",
    "        indirect_ci_upper = mediation_results.loc[mediation_results[\"path\"] == \"Indirect\", \"CI[97.5%]\"].iloc[0]\n",
    "        \n",
    "        direct_effect = mediation_results.loc[mediation_results[\"path\"] == \"X -> Y\", \"coef\"].iloc[0]\n",
    "        direct_pval = mediation_results.loc[mediation_results[\"path\"] == \"X -> Y\", \"pval\"].iloc[0]\n",
    "        \n",
    "        total_effect = mediation_results.loc[mediation_results[\"path\"] == \"Total\", \"coef\"].iloc[0]\n",
    "        total_pval = mediation_results.loc[mediation_results[\"path\"] == \"Total\", \"pval\"].iloc[0]\n",
    "        \n",
    "        x_m_effect = mediation_results.loc[mediation_results[\"path\"] == \"X -> M\", \"coef\"].iloc[0]\n",
    "        x_m_pval = mediation_results.loc[mediation_results[\"path\"] == \"X -> M\", \"pval\"].iloc[0]\n",
    "        \n",
    "        m_y_effect = mediation_results.loc[mediation_results[\"path\"] == \"M -> Y\", \"coef\"].iloc[0]\n",
    "        m_y_pval = mediation_results.loc[mediation_results[\"path\"] == \"M -> Y\", \"pval\"].iloc[0]\n",
    "\n",
    "        # Build the APA text\n",
    "        text = \"Uma análise de mediação foi conduzida para investigar se o efeito da Estratégia (X) na Recordação Livre (Y) é mediado pela Organização Semântica (ARC, M), controlando pelo Grupo (covariável). \"\n",
    "        \n",
    "        # Path X -> M\n",
    "        significance_xm = \"não foi significativo\" if x_m_pval >= 0.05 else \"foi significativo\"\n",
    "        text += f\"O efeito da Estratégia no ARC {significance_xm} (β = {x_m_effect:.3f}, {format_p_value(x_m_pval)}). \"\n",
    "        \n",
    "        # Path M -> Y\n",
    "        significance_my = \"não foi significativo\" if m_y_pval >= 0.05 else \"foi significativo\"\n",
    "        text += f\"O efeito do ARC na Recordação Livre, controlando pela Estratégia e Grupo, {significance_my} (β = {m_y_effect:.3f}, {format_p_value(m_y_pval)}). \"\n",
    "        \n",
    "        # Indirect Effect (Mediation)\n",
    "        significance_indirect = \"não foi significativo\" if indirect_pval >= 0.05 else \"foi significativo\"\n",
    "        text += f\"O efeito indireto da Estratégia na Recordação Livre através do ARC {significance_indirect} (Efeito Indireto = {indirect_effect:.3f}, IC 95% [{indirect_ci_lower:.3f}, {indirect_ci_upper:.3f}], {format_p_value(indirect_pval)}). \"\n",
    "        \n",
    "        # Direct Effect\n",
    "        significance_direct = \"não foi significativo\" if direct_pval >= 0.05 else \"foi significativo\"\n",
    "        text += f\"O efeito direto da Estratégia na Recordação Livre, controlando pelo ARC e Grupo, {significance_direct} (β = {direct_effect:.3f}, {format_p_value(direct_pval)}). \"\n",
    "        \n",
    "        # Total Effect\n",
    "        significance_total = \"não foi significativo\" if total_pval >= 0.05 else \"foi significativo\"\n",
    "        text += f\"O efeito total da Estratégia na Recordação Livre {significance_total} (β = {total_effect:.3f}, {format_p_value(total_pval)}).\"\n",
    "        \n",
    "    except (IndexError, KeyError, TypeError) as e:\n",
    "        return f\"Erro ao formatar resultados da mediação: {e}. Verifique a tabela de resultados.\"\n",
    "        \n",
    "    return text\n",
    "\n",
    "def add_analysis_to_excel(writer, sheet_name, df_results, intro_text, apa_text, img_path=None):\n",
    "    \"\"\"Adds analysis results (intro, table, APA text, image) to an Excel sheet.\"\"\"\n",
    "    workbook = writer.book\n",
    "    try:\n",
    "        # Remove default sheet if it exists and is empty\n",
    "        if \"Sheet1\" in workbook.sheetnames and len(workbook[\"Sheet1\"]._cells) == 0:\n",
    "             del workbook[\"Sheet1\"]\n",
    "    except KeyError:\n",
    "        pass # Sheet1 might not exist\n",
    "        \n",
    "    # Check if sheet already exists (relevant for append mode)\n",
    "    if sheet_name in workbook.sheetnames:\n",
    "        worksheet = workbook[sheet_name]\n",
    "        # Clear existing content? Or append? For now, let's overwrite for simplicity if sheet exists.\n",
    "        # To truly append, we'd need to find the last row.\n",
    "        # Let's assume we overwrite if the sheet exists from a previous run of *this* function call.\n",
    "        # A better approach might be needed if multiple calls write to the same sheet.\n",
    "        print(f\"Aviso: Planilha \\'{sheet_name}\\' já existe. Sobrescrevendo conteúdo.\")\n",
    "        # Clear existing content (simplistic approach)\n",
    "        for row in worksheet.iter_rows():\n",
    "            for cell in row:\n",
    "                cell.value = None\n",
    "        # Remove existing images? This is harder with openpyxl.\n",
    "    else:\n",
    "        worksheet = workbook.create_sheet(sheet_name)\n",
    "    \n",
    "    # Write Intro text first, merged cells\n",
    "    current_row = 1\n",
    "    if intro_text:\n",
    "        worksheet.cell(row=current_row, column=1, value=intro_text)\n",
    "        worksheet.merge_cells(start_row=current_row, start_column=1, end_row=current_row + 2, end_column=10) # Merge 3 rows for intro\n",
    "        worksheet.cell(row=current_row, column=1).alignment = Alignment(wrap_text=True, vertical=\"top\")\n",
    "        worksheet.cell(row=current_row, column=1).font = Font(size=11, italic=True)\n",
    "        current_row += 4 # Add a blank row after intro\n",
    "        \n",
    "    # Write APA text next, merged cells\n",
    "    if apa_text:\n",
    "        worksheet.cell(row=current_row, column=1, value=apa_text)\n",
    "        worksheet.merge_cells(start_row=current_row, start_column=1, end_row=current_row + 2, end_column=10) # Merge 3 rows for APA\n",
    "        worksheet.cell(row=current_row, column=1).alignment = Alignment(wrap_text=True, vertical=\"top\")\n",
    "        worksheet.cell(row=current_row, column=1).font = Font(size=11)\n",
    "        current_row += 4 # Add a blank row after APA text\n",
    "    \n",
    "    # Write DataFrame results below the text\n",
    "    start_row_df = current_row \n",
    "    if df_results is not None and not df_results.empty:\n",
    "        # Convert index name if it's numeric or default, otherwise keep it\n",
    "        df_to_write = df_results.copy()\n",
    "        if df_to_write.index.name is None or isinstance(df_to_write.index.name, int):\n",
    "             df_to_write.index.name = \"Index\"\n",
    "        elif df_to_write.index.name == \"path\": # Specific for mediation\n",
    "             df_to_write.index.name = \"Caminho\"\n",
    "             \n",
    "        for r_idx, row in enumerate(dataframe_to_rows(df_to_write, index=True, header=True), start_row_df):\n",
    "            for c_idx, value in enumerate(row, 1):\n",
    "                cell = worksheet.cell(row=r_idx, column=c_idx, value=value)\n",
    "                # Apply formatting for numeric values (optional)\n",
    "                if isinstance(value, (int, float)):\n",
    "                    cell.number_format = '0.000' # Example format\n",
    "                if r_idx == start_row_df: # Header row\n",
    "                    cell.font = Font(bold=True)\n",
    "        current_row += len(df_to_write) + 2 # Update current row after dataframe + blank row\n",
    "    else:\n",
    "        worksheet.cell(row=start_row_df, column=1, value=\"(Nenhuma tabela de dados para esta análise)\")\n",
    "        current_row += 2\n",
    "                \n",
    "    # Add image if path is provided\n",
    "    img_anchor_row = current_row\n",
    "    if img_path and os.path.exists(img_path):\n",
    "        try:\n",
    "            img = Image(img_path)\n",
    "            # Optional: Resize image if needed\n",
    "            # img.height = img.height * 0.5 \n",
    "            # img.width = img.width * 0.5\n",
    "            worksheet.add_image(img, f\"A{img_anchor_row}\") \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao adicionar imagem {img_path} à planilha {sheet_name}: {e}\")\n",
    "            worksheet.cell(row=img_anchor_row, column=1, value=f\"(Erro ao carregar imagem: {os.path.basename(img_path)})\" )\n",
    "    elif img_path:\n",
    "        print(f\"Aviso: Arquivo de imagem não encontrado para adicionar à planilha {sheet_name}: {img_path}\")\n",
    "        worksheet.cell(row=img_anchor_row, column=1, value=f\"(Imagem não encontrada: {os.path.basename(img_path)})\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c995de",
   "metadata": {},
   "source": [
    "## 2. Carregamento e Inspeção Inicial dos Dados\n",
    "\n",
    "Carregamos o conjunto de dados e realizamos uma inspeção inicial para verificar a estrutura, tipos de dados e primeiras linhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912cf2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados\n",
    "data_path = \"/home/ubuntu/upload/measures_phd_valid.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Exibir informações básicas\n",
    "print(\"Dimensões do DataFrame:\", df.shape)\n",
    "print(\"\\nTipos de Dados:\\n\", df.dtypes)\n",
    "print(\"\\nPrimeiras 5 linhas:\\n\", df.head())\n",
    "print(\"\\nValores Ausentes:\\n\", df.isnull().sum())\n",
    "\n",
    "# --- Categorização do Desempenho N-Back ---\n",
    "nback_col = 'nback_score'\n",
    "if nback_col in df.columns:\n",
    "    median_nback = df[nback_col].median()\n",
    "    df['nback_performance'] = df[nback_col].apply(lambda x: 'Alto' if x > median_nback else 'Baixo')\n",
    "    print(f\"Coluna 'nback_performance' criada com base na mediana ({median_nback:.2f}) de '{nback_col}'.\")\n",
    "    print(df['nback_performance'].value_counts())\n",
    "else:\n",
    "    print(f\"Aviso: Coluna '{nback_col}' não encontrada. A ANOVA 2x2x2 não pode ser realizada.\")\n",
    "    df['nback_performance'] = 'N/A' # Add placeholder column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ffde44",
   "metadata": {},
   "source": [
    "## 3. Preparação e Limpeza dos Dados\n",
    "\n",
    "Nesta seção, preparamos os dados para análise:\n",
    "*   Selecionamos as colunas relevantes.\n",
    "*   Renomeamos colunas para clareza, se necessário.\n",
    "*   **Verificamos e/ou recalculamos variáveis importantes (ex: PANAS Negativo, BAIdelta)**, conforme discussão anterior.\n",
    "*   Criamos rótulos descritivos para variáveis categóricas (Grupo, Estratégia).\n",
    "*   Tratamos valores ausentes (se houver e for necessário)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259039e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar colunas relevantes (ajustar conforme necessidade)\n",
    "relevant_cols = [\"code\", \"Group\", \"Strategy\", \"words_recalled\", \"ARC\", \n",
    "                 \"BAIpre\", \"BAIpos\", \"BAIdelta\", \n",
    "                 \"PANASpre\", \"PANASpos\", \"PANASdelta\", \n",
    "                 # Adicionar outras colunas se necessário (ex: para cálculo PANAS Negativo)\n",
    "                ]\n",
    "# df_analysis = df[relevant_cols].copy()\n",
    "\n",
    "# !! Placeholder: Recalcular/Verificar PANAS Negativo !!\n",
    "# Aqui entraria o código para calcular o PANAS Negativo, \n",
    "# garantindo que apenas os itens negativos sejam somados.\n",
    "# Exemplo hipotético (precisa ser adaptado ao seu script original):\n",
    "# panas_neg_items = [...] # Lista dos nomes das colunas dos itens negativos\n",
    "# df_analysis[\"PANASneg_pre\"] = df[panas_neg_items_pre].sum(axis=1)\n",
    "# df_analysis[\"PANASneg_pos\"] = df[panas_neg_items_pos].sum(axis=1)\n",
    "# df_analysis[\"PANASneg_delta\"] = df_analysis[\"PANASneg_pos\"] - df_analysis[\"PANASneg_pre\"]\n",
    "\n",
    "# Criar rótulos descritivos\n",
    "df[\"Group_label\"] = df[\"Group\"].map({0: \"Controle\", 1: \"Estressado\"})\n",
    "df[\"Strategy_label\"] = df[\"Strategy\"].map({0: \"Releitura\", 1: \"Prática de Lembrar\"})\n",
    "\n",
    "# Verificar novamente valores ausentes nas colunas selecionadas\n",
    "# print(\"\\nValores Ausentes (Após Seleção):\\n\", df_analysis.isnull().sum())\n",
    "\n",
    "# Tratar ausentes (se necessário - exemplo: imputação ou remoção)\n",
    "# df_analysis = df_analysis.dropna() # Exemplo: remover linhas com qualquer NA\n",
    "\n",
    "# Exibir dataframe preparado\n",
    "# print(\"\\nDataFrame Preparado:\\n\", df_analysis.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94358067",
   "metadata": {},
   "source": [
    "## 4. Análise Descritiva Detalhada\n",
    "\n",
    "Calculamos estatísticas descritivas (média, desvio padrão, N) e criamos visualizações (boxplots, histogramas) para as variáveis dependentes (ARC, `words_recalled`) e de manipulação (BAI, PANAS Negativo) por grupo e estratégia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef565d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas Descritivas\n",
    "print(\"\\n--- Estatísticas Descritivas ---\")\n",
    "\n",
    "# Exemplo para ARC\n",
    "desc_arc = df.groupby([\"Group_label\", \"Strategy_label\"])[\"ARC\"].agg([\"count\", \"mean\", \"std\"])\n",
    "print(\"\\nARC por Grupo e Estratégia:\\n\", desc_arc)\n",
    "\n",
    "# Exemplo para Words Recalled\n",
    "desc_words = df.groupby([\"Group_label\", \"Strategy_label\"])[\"words_recalled\"].agg([\"count\", \"mean\", \"std\"])\n",
    "print(\"\\nPalavras Recordadas por Grupo e Estratégia:\\n\", desc_words)\n",
    "\n",
    "# Descritivas para BAI e PANAS Negativo (pré, pós, delta) por Grupo\n",
    "# ... (código similar para BAIpre, BAIpos, BAIdelta, PANASneg_pre, PANASneg_pos, PANASneg_delta)\n",
    "\n",
    "# Visualizações\n",
    "print(\"\\n--- Gerando Visualizações Descritivas ---\")\n",
    "\n",
    "# Boxplot ARC\n",
    "plt.figure()\n",
    "sns.boxplot(x=\"Group_label\", y=\"ARC\", hue=\"Strategy_label\", data=df)\n",
    "plt.title(\"ARC por Grupo e Estratégia\")\n",
    "plt.xlabel(\"Grupo Experimental\")\n",
    "plt.ylabel(\"ARC Score\")\n",
    "plt.legend(title=\"Estratégia\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"boxplot_arc_grupo_estrategia.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Boxplot Words Recalled\n",
    "plt.figure()\n",
    "sns.boxplot(x=\"Group_label\", y=\"words_recalled\", hue=\"Strategy_label\", data=df)\n",
    "plt.title(\"Palavras Recordadas por Grupo e Estratégia\")\n",
    "plt.xlabel(\"Grupo Experimental\")\n",
    "plt.ylabel(\"Nº Palavras Recordadas\")\n",
    "plt.legend(title=\"Estratégia\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"boxplot_words_grupo_estrategia.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Boxplots para BAI e PANAS Negativo (pré/pós por grupo)\n",
    "# ... (código para gerar boxplots comparando pré e pós para BAI e PANAS Negativo)\n",
    "\n",
    "# --- Salvar Estatísticas Descritivas e Gráficos no Excel ---\n",
    "excel_path = os.path.join(output_dir, 'resultados_analise_v5.xlsx')\n",
    "intro_desc = \"Esta seção apresenta as estatísticas descritivas (média e desvio padrão) para as principais variáveis dependentes (ARC, Palavras Recordadas, BAI, PANAS) divididas pelos grupos experimentais (Grupo, Estratégia). Os gráficos de barras e interação visualizam essas médias.\"\n",
    "apa_desc = \"As médias e desvios padrão para ARC, Palavras Recordadas, BAI e PANAS por Grupo e Estratégia são apresentadas nas tabelas. Os gráficos ilustram as tendências observadas.\"\n",
    "\n",
    "# Save plots first to get paths\n",
    "img_path_arc_bar, img_path_words_bar = None, None\n",
    "img_path_arc_int, img_path_words_int = None, None\n",
    "img_path_bai_bar, img_path_panas_bar = None, None\n",
    "img_path_bai_int, img_path_panas_int = None, None\n",
    "try:\n",
    "    # ARC plots\n",
    "    fig_arc_bar = plot_descriptive_bar(df, 'ARC', 'Grupo', 'Estratégia')\n",
    "    img_path_arc_bar = os.path.join(output_dir, 'arc_barplot.png')\n",
    "    fig_arc_bar.savefig(img_path_arc_bar)\n",
    "    plt.close(fig_arc_bar)\n",
    "    fig_arc_int = plot_descriptive_interaction(df, 'ARC', 'Grupo', 'Estratégia')\n",
    "    img_path_arc_int = os.path.join(output_dir, 'arc_interacao.png')\n",
    "    fig_arc_int.savefig(img_path_arc_int)\n",
    "    plt.close(fig_arc_int)\n",
    "    # Words plots\n",
    "    fig_words_bar = plot_descriptive_bar(df, 'words_recalled', 'Grupo', 'Estratégia')\n",
    "    img_path_words_bar = os.path.join(output_dir, 'palavras_barplot.png')\n",
    "    fig_words_bar.savefig(img_path_words_bar)\n",
    "    plt.close(fig_words_bar)\n",
    "    fig_words_int = plot_descriptive_interaction(df, 'words_recalled', 'Grupo', 'Estratégia')\n",
    "    img_path_words_int = os.path.join(output_dir, 'palavras_interacao.png')\n",
    "    fig_words_int.savefig(img_path_words_int)\n",
    "    plt.close(fig_words_int)\n",
    "    # BAI plots\n",
    "    fig_bai_bar = plot_descriptive_bar(df_long_stress, 'Score', 'Grupo', 'Tempo', y_label='BAI Score')\n",
    "    img_path_bai_bar = os.path.join(output_dir, 'bai_barplot.png')\n",
    "    fig_bai_bar.savefig(img_path_bai_bar)\n",
    "    plt.close(fig_bai_bar)\n",
    "    fig_bai_int = plot_descriptive_interaction(df_long_stress, 'Score', 'Grupo', 'Tempo', y_label='BAI Score')\n",
    "    img_path_bai_int = os.path.join(output_dir, 'bai_interacao.png')\n",
    "    fig_bai_int.savefig(img_path_bai_int)\n",
    "    plt.close(fig_bai_int)\n",
    "    # PANAS plots\n",
    "    fig_panas_bar = plot_descriptive_bar(df_long_stress, 'Score', 'Grupo', 'Tempo', y_label='PANAS Negativo Score')\n",
    "    img_path_panas_bar = os.path.join(output_dir, 'panas_barplot.png')\n",
    "    fig_panas_bar.savefig(img_path_panas_bar)\n",
    "    plt.close(fig_panas_bar)\n",
    "    fig_panas_int = plot_descriptive_interaction(df_long_stress, 'Score', 'Grupo', 'Tempo', y_label='PANAS Negativo Score')\n",
    "    img_path_panas_int = os.path.join(output_dir, 'panas_interacao.png')\n",
    "    fig_panas_int.savefig(img_path_panas_int)\n",
    "    plt.close(fig_panas_int)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao gerar ou salvar gráficos descritivos: {e}\")\n",
    "    img_path_arc_bar, img_path_words_bar, img_path_arc_int, img_path_words_int = None, None, None, None\n",
    "    img_path_bai_bar, img_path_panas_bar, img_path_bai_int, img_path_panas_int = None, None, None, None\n",
    "\n",
    "# Write to Excel\n",
    "with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "    # Write each descriptive table to its own sheet\n",
    "    add_analysis_to_excel(writer, 'Desc_ARC', desc_arc, intro_desc, apa_desc, img_path_arc_int)\n",
    "    add_analysis_to_excel(writer, 'Desc_Palavras', desc_words, intro_desc, apa_desc, img_path_words_int)\n",
    "    add_analysis_to_excel(writer, 'Desc_BAI', desc_bai, intro_desc, apa_desc, img_path_bai_int)\n",
    "    add_analysis_to_excel(writer, 'Desc_PANAS', desc_panas, intro_desc, apa_desc, img_path_panas_int)\n",
    "print(f\"Estatísticas descritivas adicionadas ao Excel: {excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e99ec9",
   "metadata": {},
   "source": [
    "## 5. Verificação da Manipulação de Estresse\n",
    "\n",
    "Verificamos se a manipulação de estresse (TSST-G) foi eficaz comparando as mudanças (delta) nas medidas de ansiedade (BAI) e afeto negativo (PANAS Negativo) entre os grupos Controle e Estressado. Também comparamos os níveis pré e pós dentro de cada grupo.\n",
    "\n",
    "*   **Teste t pareado:** Compara pré vs. pós dentro de cada grupo.\n",
    "*   **Teste t independente:** Compara os deltas (pós - pré) entre os grupos.\n",
    "\n",
    "*Nota: Aplicaremos correção para múltiplas comparações posteriormente.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddd5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Verificação da Manipulação de Estresse ---\")\n",
    "\n",
    "# Separar dados por grupo\n",
    "df_control = df[df[\"Group\"] == 0]\n",
    "df_stress = df[df[\"Group\"] == 1]\n",
    "\n",
    "# Testes t pareados (Pré vs. Pós)\n",
    "bai_t_paired_control = pg.ttest(df_control[\"BAIpre\"], df_control[\"BAIpos\"], paired=True)\n",
    "bai_t_paired_stress = pg.ttest(df_stress[\"BAIpre\"], df_stress[\"BAIpos\"], paired=True)\n",
    "# panas_neg_t_paired_control = pg.ttest(df_control[\"PANASneg_pre\"], df_control[\"PANASneg_pos\"], paired=True)\n",
    "# panas_neg_t_paired_stress = pg.ttest(df_stress[\"PANASneg_pre\"], df_stress[\"PANASneg_pos\"], paired=True)\n",
    "\n",
    "print(\"\\nTeste t Pareado - BAI Controle (Pré vs Pós):\\n\", bai_t_paired_control)\n",
    "print(\"\\nTeste t Pareado - BAI Estresse (Pré vs Pós):\\n\", bai_t_paired_stress)\n",
    "# print(\"\\nTeste t Pareado - PANAS Neg Controle (Pré vs Pós):\\n\", panas_neg_t_paired_control)\n",
    "# print(\"\\nTeste t Pareado - PANAS Neg Estresse (Pré vs Pós):\\n\", panas_neg_t_paired_stress)\n",
    "\n",
    "# Testes t independentes (Comparando Deltas entre Grupos)\n",
    "bai_t_ind_delta = pg.ttest(df_control[\"BAIdelta\"], df_stress[\"BAIdelta\"], correction=False) # Assumindo variâncias iguais inicialmente\n",
    "# panas_neg_t_ind_delta = pg.ttest(df_control[\"PANASneg_delta\"], df_stress[\"PANASneg_delta\"], correction=False)\n",
    "\n",
    "print(\"\\nTeste t Independente - BAIdelta (Controle vs Estresse):\\n\", bai_t_ind_delta)\n",
    "# print(\"\\nTeste t Independente - PANASneg_delta (Controle vs Estresse):\\n\", panas_neg_t_ind_delta)\n",
    "\n",
    "# Armazenar p-valores para correção posterior\n",
    "p_values_manipulation = {\n",
    "    \"bai_paired_control\": bai_t_paired_control[\"p-val\"].iloc[0],\n",
    "    \"bai_paired_stress\": bai_t_paired_stress[\"p-val\"].iloc[0],\n",
    "    # \"panas_neg_paired_control\": panas_neg_t_paired_control[\"p-val\"].iloc[0],\n",
    "    # \"panas_neg_paired_stress\": panas_neg_t_paired_stress[\"p-val\"].iloc[0],\n",
    "    \"bai_ind_delta\": bai_t_ind_delta[\"p-val\"].iloc[0],\n",
    "    # \"panas_neg_ind_delta\": panas_neg_t_ind_delta[\"p-val\"].iloc[0]\n",
    "}\n",
    "\n",
    "# --- Salvar Verificação de Manipulação no Excel ---\n",
    "excel_path = os.path.join(output_dir, 'resultados_analise_v5.xlsx')\n",
    "intro_manip_bai = \"Esta análise verifica se a manipulação de estresse (TSST-G vs. Controle) induziu diferenças nos níveis de ansiedade (BAI) entre os grupos, antes e depois da tarefa estressora. Um teste t é usado para comparar os escores BAI pré-tarefa entre os grupos, e outro para comparar os escores pós-tarefa.\"\n",
    "intro_manip_panas = \"Similarmente à análise do BAI, esta seção verifica se a manipulação de estresse afetou os escores de afeto negativo (PANAS Negativo). Testes t comparam os escores pré e pós-tarefa entre os grupos Controle e Estressado.\"\n",
    "# Get means and SDs for APA text\n",
    "bai_stats = df.groupby('Group')['BAIpre', 'BAIpos'].agg(['mean', 'std'])\n",
    "panas_stats = df.groupby('Group')['PANASpre', 'PANASpost'].agg(['mean', 'std'])\n",
    "apa_bai_full = ''\n",
    "apa_panas_full = ''\n",
    "if t_test_bai_pre is not None:\n",
    "    m_c_pre, sd_c_pre = bai_stats.loc['Controle', ('BAIpre', 'mean')], bai_stats.loc['Controle', ('BAIpre', 'std')]\n",
    "    m_s_pre, sd_s_pre = bai_stats.loc['Estressado', ('BAIpre', 'mean')], bai_stats.loc['Estressado', ('BAIpre', 'std')]\n",
    "    apa_bai_pre = format_ttest_apa(t_test_bai_pre, 'nos níveis de BAI pré-tarefa entre os grupos', 'Controle', 'Estressado', m_c_pre, sd_c_pre, m_s_pre, sd_s_pre)\n",
    "    apa_bai_full += apa_bai_pre + ' '\n",
    "if t_test_bai_pos is not None:\n",
    "    m_c_pos, sd_c_pos = bai_stats.loc['Controle', ('BAIpos', 'mean')], bai_stats.loc['Controle', ('BAIpos', 'std')]\n",
    "    m_s_pos, sd_s_pos = bai_stats.loc['Estressado', ('BAIpos', 'mean')], bai_stats.loc['Estressado', ('BAIpos', 'std')]\n",
    "    apa_bai_pos = format_ttest_apa(t_test_bai_pos, 'nos níveis de BAI pós-tarefa entre os grupos', 'Controle', 'Estressado', m_c_pos, sd_c_pos, m_s_pos, sd_s_pos)\n",
    "    apa_bai_full += apa_bai_pos\n",
    "if t_test_panas_pre is not None:\n",
    "    m_c_pre, sd_c_pre = panas_stats.loc['Controle', ('PANASpre', 'mean')], panas_stats.loc['Controle', ('PANASpre', 'std')]\n",
    "    m_s_pre, sd_s_pre = panas_stats.loc['Estressado', ('PANASpre', 'mean')], panas_stats.loc['Estressado', ('PANASpre', 'std')]\n",
    "    apa_panas_pre = format_ttest_apa(t_test_panas_pre, 'nos níveis de PANAS Negativo pré-tarefa entre os grupos', 'Controle', 'Estressado', m_c_pre, sd_c_pre, m_s_pre, sd_s_pre)\n",
    "    apa_panas_full += apa_panas_pre + ' '\n",
    "if t_test_panas_pos is not None:\n",
    "    m_c_pos, sd_c_pos = panas_stats.loc['Controle', ('PANASpost', 'mean')], panas_stats.loc['Controle', ('PANASpost', 'std')]\n",
    "    m_s_pos, sd_s_pos = panas_stats.loc['Estressado', ('PANASpost', 'mean')], panas_stats.loc['Estressado', ('PANASpost', 'std')]\n",
    "    apa_panas_pos = format_ttest_apa(t_test_panas_pos, 'nos níveis de PANAS Negativo pós-tarefa entre os grupos', 'Controle', 'Estressado', m_c_pos, sd_c_pos, m_s_pos, sd_s_pos)\n",
    "    apa_panas_full += apa_panas_pos\n",
    "\n",
    "# Combine result tables for Excel sheet\n",
    "bai_results_combined = pd.concat([t_test_bai_pre.assign(Comparacao='BAI Pré'), t_test_bai_pos.assign(Comparacao='BAI Pós')], ignore_index=True) if t_test_bai_pre is not None and t_test_bai_pos is not None else (t_test_bai_pre.assign(Comparacao='BAI Pré') if t_test_bai_pre is not None else t_test_bai_pos.assign(Comparacao='BAI Pós'))\n",
    "panas_results_combined = pd.concat([t_test_panas_pre.assign(Comparacao='PANAS Pré'), t_test_panas_pos.assign(Comparacao='PANAS Pós')], ignore_index=True) if t_test_panas_pre is not None and t_test_panas_pos is not None else (t_test_panas_pre.assign(Comparacao='PANAS Pré') if t_test_panas_pre is not None else t_test_panas_pos.assign(Comparacao='PANAS Pós'))\n",
    "\n",
    "# Append to Excel\n",
    "with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    if bai_results_combined is not None:\n",
    "        add_analysis_to_excel(writer, 'Manipulacao_BAI', bai_results_combined, intro_manip_bai, apa_bai_full)\n",
    "    if panas_results_combined is not None:\n",
    "        add_analysis_to_excel(writer, 'Manipulacao_PANAS', panas_results_combined, intro_manip_panas, apa_panas_full)\n",
    "print(f\"Resultados da verificação de manipulação adicionados ao Excel: {excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ed2bb",
   "metadata": {},
   "source": [
    "## 6. Verificação dos Pressupostos Estatísticos (ANOVA)\n",
    "\n",
    "Antes de realizar a ANOVA, verificamos seus principais pressupostos:\n",
    "1.  **Normalidade dos Resíduos:** Os resíduos do modelo ANOVA devem seguir uma distribuição normal (Teste de Shapiro-Wilk).\n",
    "2.  **Homogeneidade das Variâncias (Homocedasticidade):** As variâncias dos grupos devem ser aproximadamente iguais (Teste de Levene).\n",
    "\n",
    "Realizaremos esses testes para as variáveis dependentes principais: ARC e `words_recalled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbdac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Verificação dos Pressupostos da ANOVA ---\")\n",
    "\n",
    "# Pressupostos para ARC\n",
    "print(\"\\n** Verificando pressupostos para ARC **\")\n",
    "# Ajustar modelo ANOVA para obter resíduos\n",
    "model_arc = ols(\"ARC ~ C(Group) * C(Strategy)\", data=df).fit()\n",
    "residuals_arc = model_arc.resid\n",
    "\n",
    "# 1. Normalidade dos Resíduos (Shapiro-Wilk)\n",
    "shapiro_arc = stats.shapiro(residuals_arc)\n",
    "print(f\"Teste de Shapiro-Wilk (Normalidade dos Resíduos ARC): W={shapiro_arc.statistic:.4f}, p={shapiro_arc.pvalue:.4f}\")\n",
    "if shapiro_arc.pvalue < 0.05:\n",
    "    print(\"-> Atenção: Resíduos para ARC podem não ser normalmente distribuídos.\")\n",
    "else:\n",
    "    print(\"-> Resíduos para ARC parecem normalmente distribuídos.\")\n",
    "\n",
    "# 2. Homogeneidade das Variâncias (Levene)\n",
    "levene_arc = pg.homoscedasticity(data=df, dv=\"ARC\", group=\"Group\", method=\"levene\")\n",
    "print(f\"\\nTeste de Levene (Homocedasticidade ARC por Grupo): W={levene_arc[\"W\"].iloc[0]:.4f}, p={levene_arc[\"pval\"].iloc[0]:.4f}\")\n",
    "if levene_arc[\"pval\"].iloc[0] < 0.05:\n",
    "    print(\"-> Atenção: Variâncias para ARC podem não ser homogêneas entre os Grupos.\")\n",
    "else:\n",
    "    print(\"-> Variâncias para ARC parecem homogêneas entre os Grupos.\")\n",
    "\n",
    "levene_arc_strategy = pg.homoscedasticity(data=df, dv=\"ARC\", group=\"Strategy\", method=\"levene\")\n",
    "print(f\"Teste de Levene (Homocedasticidade ARC por Estratégia): W={levene_arc_strategy[\"W\"].iloc[0]:.4f}, p={levene_arc_strategy[\"pval\"].iloc[0]:.4f}\")\n",
    "# ... (interpretação similar)\n",
    "\n",
    "# Pressupostos para words_recalled\n",
    "print(\"\\n** Verificando pressupostos para Palavras Recordadas **\")\n",
    "# ... (código similar ao de ARC para words_recalled)\n",
    "\n",
    "# Nota: Se os pressupostos forem violados, considerar transformações ou testes não paramétricos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a783635",
   "metadata": {},
   "source": [
    "## 7. Análises Principais: ANOVA Fatorial 2x2\n",
    "\n",
    "Realizamos ANOVAs fatoriais 2 (Grupo: Controle vs. Estresse) × 2 (Estratégia: Releitura vs. Prática de Lembrar) para as variáveis dependentes principais:\n",
    "*   ARC (Adjusted Ratio of Clustering)\n",
    "*   `words_recalled` (Número de Palavras Recordadas)\n",
    "\n",
    "Reportamos os efeitos principais (Grupo, Estratégia) e o efeito de interação (Grupo × Estratégia), incluindo os tamanhos de efeito (Eta-squared parcial, η²p)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab03f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ANOVA Fatorial 2x2x2 (Grupo x Estratégia x N-Back) ---\n",
    "import pingouin as pg\n",
    "\n",
    "# ANOVA para ARC\n",
    "aov_arc_2x2x2 = None\n",
    "apa_arc_2x2x2 = 'ANOVA 2x2x2 para ARC não realizada (verificar coluna nback_performance).'\n",
    "if 'nback_performance' in df.columns and df['nback_performance'].nunique() > 1:\n",
    "    try:\n",
    "        aov_arc_2x2x2 = pg.anova(data=df, dv='ARC', between=['Group', 'Strategy', 'nback_performance'], detailed=True)\n",
    "        print(\"\n",
    "ANOVA 2x2x2 para ARC:\")\n",
    "        print(aov_arc_2x2x2)\n",
    "        apa_arc_2x2x2 = format_anova_apa_v5(aov_arc_2x2x2, 'ARC')\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao calcular ANOVA 2x2x2 para ARC: {e}\")\n",
    "        apa_arc_2x2x2 = f\"Erro ao calcular ANOVA 2x2x2 para ARC: {e}\"\n",
    "else:\n",
    "    print(\"Coluna 'nback_performance' não é adequada para ANOVA 2x2x2.\")\n",
    "\n",
    "# ANOVA para Palavras Recordadas\n",
    "aov_words_2x2x2 = None\n",
    "apa_words_2x2x2 = 'ANOVA 2x2x2 para Palavras Recordadas não realizada (verificar coluna nback_performance).'\n",
    "if 'nback_performance' in df.columns and df['nback_performance'].nunique() > 1:\n",
    "    try:\n",
    "        aov_words_2x2x2 = pg.anova(data=df, dv='words_recalled', between=['Group', 'Strategy', 'nback_performance'], detailed=True)\n",
    "        print(\"\n",
    "ANOVA 2x2x2 para Palavras Recordadas:\")\n",
    "        print(aov_words_2x2x2)\n",
    "        apa_words_2x2x2 = format_anova_apa_v5(aov_words_2x2x2, 'Palavras Recordadas')\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao calcular ANOVA 2x2x2 para Palavras Recordadas: {e}\")\n",
    "        apa_words_2x2x2 = f\"Erro ao calcular ANOVA 2x2x2 para Palavras Recordadas: {e}\"\n",
    "else:\n",
    "    print(\"Coluna 'nback_performance' não é adequada para ANOVA 2x2x2.\")\n",
    "\n",
    "# --- Salvar Resultados da ANOVA 2x2x2 no Excel ---\n",
    "excel_path = os.path.join(output_dir, 'resultados_analise_v5.xlsx')\n",
    "intro_anova = \"Esta análise utiliza uma ANOVA fatorial 2x2x2 para investigar os efeitos principais e as interações entre Grupo (Controle vs. Estresse), Estratégia de Aprendizagem (Releitura vs. Prática de Lembrar) e Desempenho na Tarefa N-Back (Baixo vs. Alto) nas medidas de memória (ARC e Palavras Recordadas). Permite verificar se o desempenho cognitivo basal (N-Back) modula os efeitos do estresse e da estratégia na memória.\"\n",
    "with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    if aov_arc_2x2x2 is not None:\n",
    "        add_analysis_to_excel(writer, 'ANOVA_ARC_2x2x2', aov_arc_2x2x2, intro_anova, apa_arc_2x2x2)\n",
    "    if aov_words_2x2x2 is not None:\n",
    "        add_analysis_to_excel(writer, 'ANOVA_Words_2x2x2', aov_words_2x2x2, intro_anova, apa_words_2x2x2)\n",
    "print(f\"Resultados da ANOVA 2x2x2 adicionados ao Excel: {excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1833e0a",
   "metadata": {},
   "source": [
    "## 8. Análise da Hipótese e Efeitos de Interação\n",
    "\n",
    "Analisamos especificamente a hipótese principal: \"o estresse diminui os scores de evocação total e ARC, e essa diminuição será menor ou inexistente no grupo que usou Prática de Lembrar\".\n",
    "\n",
    "Isso envolve examinar o efeito de interação. Como a interação não foi significativa nas análises preliminares (e seguindo a instrução do usuário), **enfatizaremos a ausência de evidência estatística para a interação**.\n",
    "\n",
    "Realizaremos comparações planejadas (testes t) para explorar os efeitos simples (efeito do estresse dentro de cada estratégia), aplicando correção para múltiplas comparações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10278291",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Análise da Hipótese e Efeitos de Interação ---\")\n",
    "\n",
    "# Interpretação da Interação (com base nos resultados da ANOVA)\n",
    "interaction_p_arc = anova_arc.loc[anova_arc[\"Source\"] == \"Group * Strategy\", \"p-unc\"].iloc[0]\n",
    "interaction_p_words = anova_words.loc[anova_words[\"Source\"] == \"Group * Strategy\", \"p-unc\"].iloc[0]\n",
    "\n",
    "print(f\"\\nInteração Grupo x Estratégia para ARC: p = {interaction_p_arc:.4f}\")\n",
    "print(f\"Interação Grupo x Estratégia para Palavras Recordadas: p = {interaction_p_words:.4f}\")\n",
    "\n",
    "if interaction_p_arc >= 0.05:\n",
    "    print(\"-> Não há evidência estatística de interação significativa para ARC.\")\n",
    "if interaction_p_words >= 0.05:\n",
    "    print(\"-> Não há evidência estatística de interação significativa para Palavras Recordadas.\")\n",
    "\n",
    "# Comparações Planejadas (Efeito do Estresse dentro de cada Estratégia)\n",
    "# Separar dados por estratégia\n",
    "df_releitura = df[df[\"Strategy\"] == 0]\n",
    "df_pratica = df[df[\"Strategy\"] == 1]\n",
    "\n",
    "# Teste t: Controle vs Estresse (dentro da Releitura)\n",
    "arc_t_releitura = pg.ttest(df_releitura[df_releitura[\"Group\"] == 0][\"ARC\"], \n",
    "                             df_releitura[df_releitura[\"Group\"] == 1][\"ARC\"], correction=False)\n",
    "words_t_releitura = pg.ttest(df_releitura[df_releitura[\"Group\"] == 0][\"words_recalled\"], \n",
    "                               df_releitura[df_releitura[\"Group\"] == 1][\"words_recalled\"], correction=False)\n",
    "\n",
    "# Teste t: Controle vs Estresse (dentro da Prática de Lembrar)\n",
    "arc_t_pratica = pg.ttest(df_pratica[df_pratica[\"Group\"] == 0][\"ARC\"], \n",
    "                           df_pratica[df_pratica[\"Group\"] == 1][\"ARC\"], correction=False)\n",
    "words_t_pratica = pg.ttest(df_pratica[df_pratica[\"Group\"] == 0][\"words_recalled\"], \n",
    "                             df_pratica[df_pratica[\"Group\"] == 1][\"words_recalled\"], correction=False)\n",
    "\n",
    "print(\"\\n-- Comparações Planejadas (Testes t) --\")\n",
    "print(\"\\nARC - Efeito do Estresse (Releitura):\\n\", arc_t_releitura)\n",
    "print(\"\\nARC - Efeito do Estresse (Prática):\\n\", arc_t_pratica)\n",
    "print(\"\\nPalavras - Efeito do Estresse (Releitura):\\n\", words_t_releitura)\n",
    "print(\"\\nPalavras - Efeito do Estresse (Prática):\\n\", words_t_pratica)\n",
    "\n",
    "# Coletar p-valores para correção\n",
    "p_values_planned = {\n",
    "    \"arc_releitura\": arc_t_releitura[\"p-val\"].iloc[0],\n",
    "    \"arc_pratica\": arc_t_pratica[\"p-val\"].iloc[0],\n",
    "    \"words_releitura\": words_t_releitura[\"p-val\"].iloc[0],\n",
    "    \"words_pratica\": words_t_pratica[\"p-val\"].iloc[0]\n",
    "}\n",
    "\n",
    "# Combinar todos os p-valores que precisam de correção\n",
    "all_p_values = {**p_values_manipulation, **p_values_planned}\n",
    "p_list = list(all_p_values.values())\n",
    "keys_list = list(all_p_values.keys())\n",
    "\n",
    "# Aplicar correção (ex: Bonferroni ou FDR)\n",
    "reject_bonferroni, pvals_corrected_bonf, _, _ = multipletests(p_list, alpha=0.05, method='bonferroni')\n",
    "reject_fdr, pvals_corrected_fdr, _, _ = multipletests(p_list, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "print(\"\\n-- Correção para Múltiplas Comparações --\")\n",
    "results_correction = pd.DataFrame({\n",
    "    \"Teste\": keys_list,\n",
    "    \"p_original\": p_list,\n",
    "    \"p_corrigido_Bonf\": pvals_corrected_bonf,\n",
    "    \"Significativo_Bonf\": reject_bonferroni,\n",
    "    \"p_corrigido_FDR\": pvals_corrected_fdr,\n",
    "    \"Significativo_FDR\": reject_fdr\n",
    "})\n",
    "print(results_correction)\n",
    "\n",
    "print(\"\\nInterpretar resultados com base nos p-valores corrigidos.\")\n",
    "\n",
    "# --- Salvar Comparações Planejadas no Excel ---\n",
    "excel_path = os.path.join(output_dir, 'resultados_analise_v5.xlsx')\n",
    "intro_planned = \"Após a ANOVA, comparações planejadas (testes t) são realizadas para investigar hipóteses específicas sobre as diferenças entre condições particulares (e.g., comparar Prática de Lembrar vs. Releitura dentro do grupo Estressado). Isso permite um exame mais focado dos efeitos encontrados.\"\n",
    "# Combine all planned comparison results into one DataFrame for the sheet\n",
    "all_planned_results = []\n",
    "apa_planned_full = ''\n",
    "# ARC Comparisons\n",
    "if comp_arc_rp_control is not None:\n",
    "    all_planned_results.append(comp_arc_rp_control.assign(Comparacao='ARC: RP vs Rel (Controle)'))\n",
    "    apa_planned_full += format_ttest_apa(comp_arc_rp_control, 'entre Prática de Lembrar e Releitura no ARC (Grupo Controle)') + ' '\n",
    "if comp_arc_rp_stress is not None:\n",
    "    all_planned_results.append(comp_arc_rp_stress.assign(Comparacao='ARC: RP vs Rel (Estresse)'))\n",
    "    apa_planned_full += format_ttest_apa(comp_arc_rp_stress, 'entre Prática de Lembrar e Releitura no ARC (Grupo Estresse)') + ' '\n",
    "if comp_arc_control_stress_rel is not None:\n",
    "    all_planned_results.append(comp_arc_control_stress_rel.assign(Comparacao='ARC: Controle vs Estresse (Releitura)'))\n",
    "    apa_planned_full += format_ttest_apa(comp_arc_control_stress_rel, 'entre Controle e Estresse no ARC (Estratégia Releitura)') + ' '\n",
    "if comp_arc_control_stress_rp is not None:\n",
    "    all_planned_results.append(comp_arc_control_stress_rp.assign(Comparacao='ARC: Controle vs Estresse (RP)'))\n",
    "    apa_planned_full += format_ttest_apa(comp_arc_control_stress_rp, 'entre Controle e Estresse no ARC (Estratégia Prática de Lembrar)') + ' '\n",
    "# Words Recalled Comparisons\n",
    "if comp_words_rp_control is not None:\n",
    "    all_planned_results.append(comp_words_rp_control.assign(Comparacao='Palavras: RP vs Rel (Controle)'))\n",
    "    apa_planned_full += format_ttest_apa(comp_words_rp_control, 'entre Prática de Lembrar e Releitura em Palavras Recordadas (Grupo Controle)') + ' '\n",
    "if comp_words_rp_stress is not None:\n",
    "    all_planned_results.append(comp_words_rp_stress.assign(Comparacao='Palavras: RP vs Rel (Estresse)'))\n",
    "    apa_planned_full += format_ttest_apa(comp_words_rp_stress, 'entre Prática de Lembrar e Releitura em Palavras Recordadas (Grupo Estresse)') + ' '\n",
    "if comp_words_control_stress_rel is not None:\n",
    "    all_planned_results.append(comp_words_control_stress_rel.assign(Comparacao='Palavras: Controle vs Estresse (Releitura)'))\n",
    "    apa_planned_full += format_ttest_apa(comp_words_control_stress_rel, 'entre Controle e Estresse em Palavras Recordadas (Estratégia Releitura)') + ' '\n",
    "if comp_words_control_stress_rp is not None:\n",
    "    all_planned_results.append(comp_words_control_stress_rp.assign(Comparacao='Palavras: Controle vs Estresse (RP)'))\n",
    "    apa_planned_full += format_ttest_apa(comp_words_control_stress_rp, 'entre Controle e Estresse em Palavras Recordadas (Estratégia Prática de Lembrar)') + ' '\n",
    "# Combine results if any exist\n",
    "if all_planned_results:\n",
    "    planned_results_combined = pd.concat(all_planned_results, ignore_index=True)\n",
    "    # Append to Excel\n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "        add_analysis_to_excel(writer, 'Comparacoes_Planejadas', planned_results_combined, intro_planned, apa_planned_full.strip())\n",
    "    print(f\"Comparações planejadas adicionadas ao Excel: {excel_path}\")\n",
    "else:\n",
    "    print(\"Nenhuma comparação planejada foi realizada ou gerou resultados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf6fb1",
   "metadata": {},
   "source": [
    "## 9. Visualizações dos Resultados Principais\n",
    "\n",
    "Criamos gráficos de interação para visualizar os padrões dos efeitos principais e da interação (mesmo que não significativa) para ARC e `words_recalled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2944d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Visualizações dos Resultados Principais ---\")\n",
    "\n",
    "# Gráfico de Interação para ARC\n",
    "plt.figure()\n",
    "sns.pointplot(x=\"Group_label\", y=\"ARC\", hue=\"Strategy_label\", data=df, \n",
    "              markers=[\"o\", \"s\"], linestyles=[\"-\", \"--\"], dodge=True, errorbar=\"se\")\n",
    "plt.title(\"Gráfico de Interação: ARC por Grupo e Estratégia\")\n",
    "plt.xlabel(\"Grupo Experimental\")\n",
    "plt.ylabel(\"ARC Score Médio (± Erro Padrão)\")\n",
    "plt.legend(title=\"Estratégia\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"interaction_plot_arc.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de Interação para Words Recalled\n",
    "plt.figure()\n",
    "sns.pointplot(x=\"Group_label\", y=\"words_recalled\", hue=\"Strategy_label\", data=df, \n",
    "              markers=[\"o\", \"s\"], linestyles=[\"-\", \"--\"], dodge=True, errorbar=\"se\")\n",
    "plt.title(\"Gráfico de Interação: Palavras Recordadas por Grupo e Estratégia\")\n",
    "plt.xlabel(\"Grupo Experimental\")\n",
    "plt.ylabel(\"Nº Palavras Recordadas Médio (± Erro Padrão)\")\n",
    "plt.legend(title=\"Estratégia\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"interaction_plot_words.png\"))\n",
    "plt.show()\n",
    "\n",
    "# --- Salvar Correção de Comparações Múltiplas no Excel ---\n",
    "excel_path = os.path.join(output_dir, 'resultados_analise_v5.xlsx')\n",
    "intro_corr = \"Dado que múltiplas comparações planejadas foram realizadas, é necessário corrigir os p-valores para controlar a taxa de erro Tipo I (falsos positivos). O método de Bonferroni-Holm é aplicado aqui aos p-valores das comparações planejadas.\"\n",
    "# Create APA text summarizing the correction\n",
    "apa_corr_full = 'Os p-valores das comparações planejadas foram ajustados usando a correção de Bonferroni-Holm para controlar a taxa de erro Tipo I. '\n",
    "if 'p-corr' in planned_results_combined.columns:\n",
    "    significant_after_corr = planned_results_combined[planned_results_combined['p-corr'] < 0.05]\n",
    "    if not significant_after_corr.empty:\n",
    "        apa_corr_full += 'As seguintes comparações permaneceram significativas após a correção: '\n",
    "        apa_corr_full += ', '.join(significant_after_corr['Comparacao'].tolist()) + '.'\n",
    "    else:\n",
    "        apa_corr_full += 'Nenhuma comparação permaneceu significativa após a correção.'\n",
    "else:\n",
    "    apa_corr_full += 'A correção não pôde ser aplicada (verificar resultados anteriores).'\n",
    "    planned_results_combined = pd.DataFrame({'Status': ['Correção não aplicada']}) # Placeholder df\n",
    "\n",
    "# Append to Excel\n",
    "with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    add_analysis_to_excel(writer, 'Correcao_Multipla', planned_results_combined[['Comparacao', 'p-val', 'p-corr', 'significant']], intro_corr, apa_corr_full)\n",
    "print(f\"Resultados da correção de comparações múltiplas adicionados ao Excel: {excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a4b43",
   "metadata": {},
   "source": [
    "## 10. Análise de Outliers (Placeholder)\n",
    "\n",
    "Esta seção é reservada para a análise e tratamento de outliers.\n",
    "\n",
    "*   Identificar outliers (ex: Z-score > 3 ou critério baseado em IQR).\n",
    "*   Analisar o impacto dos outliers nos resultados.\n",
    "*   Decidir sobre o tratamento (manter, remover, transformar) e justificar.\n",
    "\n",
    "*(A implementação será definida após discussão com o usuário).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1cf0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder para código de análise de outliers\n",
    "print(\"\\n--- Análise de Outliers (a ser definida) ---\")\n",
    "\n",
    "# Exemplo: Identificação via Z-score\n",
    "# from scipy.stats import zscore\n",
    "# numeric_cols = [\"ARC\", \"words_recalled\", \"BAIdelta\", \"PANASneg_delta\"]\n",
    "# z_scores = df[numeric_cols].apply(zscore)\n",
    "# outliers = (np.abs(z_scores) > 3).any(axis=1)\n",
    "# print(f\"Número de participantes identificados como outliers (Z > 3): {outliers.sum()}\")\n",
    "# print(\"IDs dos outliers:\", df.loc[outliers, \"code\"].tolist())\n",
    "\n",
    "# Próximos passos: Discutir critérios e tratamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d2c38e",
   "metadata": {},
   "source": [
    "## 11. Conclusão e Resumo dos Achados\n",
    "\n",
    "Resumo dos principais resultados estatísticos, considerando os p-valores corrigidos e os tamanhos de efeito.\n",
    "\n",
    "*   Eficácia da manipulação de estresse.\n",
    "*   Efeitos principais de Grupo e Estratégia na memória (ARC e palavras recordadas).\n",
    "*   Ausência de interação significativa Grupo × Estratégia.\n",
    "*   Resultados das comparações planejadas (efeito do estresse dentro de cada estratégia).\n",
    "*   Implicações e próximos passos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c880430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder para resumo textual ou tabelas finais\n",
    "print(\"\\n--- Conclusão e Resumo dos Achados (a ser preenchido) ---\")\n",
    "\n",
    "# Exemplo: Criar tabela resumo\n",
    "# summary_table = ...\n",
    "# print(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc7fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Análise de Mediação (Estratégia -> ARC -> Palavras Recordadas | Grupo) ---\n",
    "import pingouin as pg\n",
    "\n",
    "mediation_results = None\n",
    "apa_mediation = 'Análise de mediação não realizada.'\n",
    "try:\n",
    "    mediation_results = pg.mediation_analysis(data=df, x='Strategy', m='ARC', y='words_recalled', covar=['Group'], n_boot=5000, seed=42)\n",
    "    print(\"\n",
    "Resultados da Análise de Mediação:\")\n",
    "    print(mediation_results)\n",
    "    apa_mediation = format_mediation_apa(mediation_results)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao calcular Análise de Mediação: {e}\")\n",
    "    apa_mediation = f\"Erro ao calcular Análise de Mediação: {e}\"\n",
    "\n",
    "# --- Salvar Resultados da Mediação no Excel ---\n",
    "excel_path = os.path.join(output_dir, 'resultados_analise_v5.xlsx')\n",
    "intro_mediation = \"Esta análise investiga se a relação entre a Estratégia de Aprendizagem e o número de Palavras Recordadas é explicada (mediada) pela Organização Semântica (ARC), controlando pelo efeito do Grupo Experimental (Estresse vs. Controle). Utiliza bootstrapping para estimar o efeito indireto.\"\n",
    "with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    if mediation_results is not None:\n",
    "        add_analysis_to_excel(writer, 'Analise_Mediacao', mediation_results, intro_mediation, apa_mediation)\n",
    "print(f\"Resultados da Análise de Mediação adicionados ao Excel: {excel_path}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
